"use strict";(self.webpackChunk_callstack_byorg_docs=self.webpackChunk_callstack_byorg_docs||[]).push([["930"],{6487:function(e,r,a){a.r(r),a.d(r,{default:function(){return o}});var s=a(651),n=a(6971);function d(e){let r=Object.assign({h1:"h1",a:"a",h2:"h2",p:"p",h3:"h3",pre:"pre",code:"code"},(0,n.ah)(),e.components);return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(r.h1,{id:"chat-model",children:["Chat Model",(0,s.jsx)(r.a,{className:"header-anchor","aria-hidden":"true",href:"#chat-model",children:"#"})]}),"\n",(0,s.jsxs)(r.h2,{id:"providers-and-adapter",children:["Providers and Adapter",(0,s.jsx)(r.a,{className:"header-anchor","aria-hidden":"true",href:"#providers-and-adapter",children:"#"})]}),"\n",(0,s.jsxs)(r.p,{children:["You can use any AI provider supported by Vercel’s ",(0,s.jsx)(r.a,{href:"https://sdk.vercel.ai/providers/ai-sdk-providers",target:"_blank",rel:"noopener noreferrer",children:"AI SDK"}),". This includes both LLM-as-a-service providers like OpenAI, Anthropic, and others, as well as locally hosted LLMs. We are also open to extending support to other types of chat models, such as LangChain’s ",(0,s.jsx)(r.a,{href:"https://js.langchain.com/docs/how_to/streaming",target:"_blank",rel:"noopener noreferrer",children:"runnables"}),"."]}),"\n",(0,s.jsxs)(r.h3,{id:"providers-examples",children:["Providers Examples",(0,s.jsx)(r.a,{className:"header-anchor","aria-hidden":"true",href:"#providers-examples",children:"#"})]}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-js",children:"import { createOpenAI } from '@ai-sdk/openai';\n\nconst openAiProvider = createOpenAI({\n  apiKey: 'your-api-key',\n  compatibility: 'strict',\n});\n"})}),"\n",(0,s.jsxs)(r.p,{children:["After instantiating the provider client, wrap it with our ",(0,s.jsx)(r.code,{children:"VercelAdapter"})," class:"]}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-js",children:"import { VercelChatModelAdapter } from '@callstack/byorg-core';\n\nconst openAiChatModel = new VercelChatModelAdapter({\n  languageModel: openAiModel,\n});\n"})}),"\n",(0,s.jsxs)(r.p,{children:["Now that the ",(0,s.jsx)(r.code,{children:"chatModel"})," is ready, let’s discuss the ",(0,s.jsx)(r.code,{children:"systemPrompt"})," function."]})]})}function t(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:r}=Object.assign({},(0,n.ah)(),e.components);return r?(0,s.jsx)(r,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}let o=t;t.__RSPRESS_PAGE_META={},t.__RSPRESS_PAGE_META["docs%2Fcore%2Fchat-model.md"]={toc:[{text:"Providers and Adapter",id:"providers-and-adapter",depth:2},{text:"Providers Examples",id:"providers-examples",depth:3}],title:"Chat Model",frontmatter:{}}}}]);